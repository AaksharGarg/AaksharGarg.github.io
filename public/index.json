[{"content":" Agentic AI system that crawls government procurement portals. Intelligent URL and RFP classification using LLMs + TF-IDF, Jaccard, and embeddings. Scalable backend using FastAPI, ChromaDB, Redis, Celery, and Docker. ","date":"3 October 2025","externalUrl":null,"permalink":"/projects/autorfp/","section":"Projects (many more to come...)","summary":"Agentic AI system for autonomous RFP discovery and prioritization.","title":"AutoRFP – GenAI Framework","type":"projects"},{"content":" Demo Video # Overview # Developed a 6-DOF robotic manipulator with AI-based perception and point-cloud-driven mapping.\nKey Work # YOLOv8 instance segmentation for payload surface extraction Point cloud processing using PCL and Open3D OctoMap generation and TF calculation ROS + MoveIt integration for motion planning Tech Stack # YOLOv8 · OpenCV · Open3D · PCL · ROS · MoveIt · Python · C++\n","date":"1 May 2024","externalUrl":null,"permalink":"/projects/6dof-robotic-arm/","section":"Projects (many more to come...)","summary":"Vision-guided robotic manipulator with perception, mapping, and motion planning.","title":"6-DOF Robotic Arm","type":"projects"},{"content":"-Developing an agentic AI system with a Streamlit UI that autonomously crawls government procurement portals to discover new RFP sources. -Implementing intelligent URL and RFP classification using LLM agents (Ollama + LangChain) combined with ML similarity methods like TF-IDF, Jaccard similarity, and vector embeddings. -Developing scalable backend using ChromaDB, Redis, FastAPI, and Docker, delivering prioritized RFPs autonomosly.\n","date":"3 May 2025","externalUrl":null,"permalink":"/projects/rag-gpu-advisor/","section":"Projects (many more to come...)","summary":"Full-stack RAG system for GPU recommendation and research.","title":"RAG-Based GPU Advisor","type":"projects"},{"content":" Demo Video # Overview # Ongoing development of a rectangular-base hexapod robot equipped with six 3-DOF legs, focusing on stable locomotion using a tripod gait and accurate inverse kinematics (IK) for planar terrain traversal.\nThe project emphasizes realistic simulation, modular control pipelines, and extensibility toward autonomous navigation on uneven terrain.\nKey Contributions # Designed and implemented tripod gait inverse kinematics for a rectangular-base hexapod. Developed kinematic models for six independent 3-DOF robotic legs. Built a full GZ-Harmonic simulation of the hexapod robot. Integrated a trajectory control plugin for smooth and synchronized leg motion. Validated gait stability and traversal performance on planar terrain in simulation. Simulation \u0026amp; Control # Accurate URDF/XACRO modeling for multi-legged locomotion. Gait phase coordination to ensure static stability. Trajectory interpolation for continuous foot motion. Future Scope # Integration of ORB-SLAM for localization and mapping. Development of terrain-adaptive IK using OctoMap. Integration with MoveIt for advanced motion planning. Extension from planar traversal to uneven and unstructured terrain. Tech Stack # Middleware \u0026amp; Simulation: ROS 2, GZ-Harmonic Robotics: Hexapod Inverse Kinematics, Gait Planning Motion \u0026amp; Planning: Trajectory Control Plugins Programming: Python, C++ ","date":"1 January 2025","externalUrl":null,"permalink":"/projects/hexabot/","section":"Projects (many more to come...)","summary":"Tripod gait inverse kinematics and simulation for a 6-legged robot with 3-DOF legs.","title":"Hexapod Robot — Tripod Gait \u0026 IK","type":"projects"},{"content":"Duration: Sep 2023 – Mar 2024\nMode: Remote\nDemo Video # Developed an autonomous quadcopter to explore terrain using object detection, clustering, and waypoint navigation. Implemented WhyCon-based localization and object detection pipelines. Designed a custom ROS message format for Swift drone communication. Fine-tuned flight stability and accuracy using PID control and Beta Flight controller. Tech Stack # ROS 2, OpenCV, PID Controller, WHYCON, Python, RViz, Gazebo\n","date":"3 October 2024","externalUrl":null,"permalink":"/projects/luminosity_drone/","section":"Projects (many more to come...)","summary":"Autonomous quadcopter for exploration, object detection, and waypoint navigation.","title":"Luminosity Drone (Quadcopter)","type":"projects"},{"content":"Duration: Dec 2023 – Jan 2024\nMode: Online (Simulation)\nBuilt a ROS 2 simulation for a differential drive robot capable of autonomous person-following. Used Kinect depth camera data for depth estimation and pose tracking. Implemented semantic image segmentation using MediaPipe. Developed centroid calculation and PID controller for smooth and stable tracking. Demo Video # Tech Stack # ROS 2, YOLOv8, MediaPipe, Python, OpenCV, Docker, RViz, Gazebo\nHardware (Simulation) # Microsoft Kinect Depth Camera, Differential Drive Robot\n","date":"3 December 2024","externalUrl":null,"permalink":"/projects/person_follower/","section":"Projects (many more to come...)","summary":"ROS 2-based differential drive robot for person following using depth and pose estimation.","title":"Person Follower Robot","type":"projects"},{"content":" Executed complex SQL queries for KPI extraction. Used CTEs, nested queries, conditional logic, and aggregations. Combined SQL with Python and Excel for insights and reporting. ","date":"12 July 2025","externalUrl":null,"permalink":"/projects/netflix-sql/","section":"Projects (many more to come...)","summary":"Advanced SQL analytics for business insights.","title":"Netflix Dataset Analysis","type":"projects"},{"content":"","date":"1 November 2025","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":" Automated extraction from unstructured enterprise data sources. Built ML-ready datasets using EDA and feature engineering. Deployed ensemble learning POCs with MongoDB-backed services. Worked directly with clients on RFP discussions and delivery timelines. ","date":"1 November 2025","externalUrl":null,"permalink":"/experience/tata-autocomp/","section":"Experience","summary":"Enterprise AI systems, data pipelines, and ML-driven automation.","title":"AI Intern — TATA AutoComp Systems Ltd.","type":"experience"},{"content":"","date":"1 November 2025","externalUrl":null,"permalink":"/tags/data-engineering/","section":"Tags","summary":"","title":"Data Engineering","type":"tags"},{"content":"","date":"1 November 2025","externalUrl":null,"permalink":"/experience/","section":"Experience","summary":"","title":"Experience","type":"experience"},{"content":"{{\u0026lt; rotating_widget \u0026gt;}}\n{{\u0026lt; home_cta \u0026gt;}}\n","date":"1 November 2025","externalUrl":null,"permalink":"/","section":"Home","summary":"","title":"Home","type":"page"},{"content":"","date":"1 November 2025","externalUrl":null,"permalink":"/tags/ml/","section":"Tags","summary":"","title":"ML","type":"tags"},{"content":"","date":"1 November 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"3 October 2025","externalUrl":null,"permalink":"/tags/fastapi/","section":"Tags","summary":"","title":"FastAPI","type":"tags"},{"content":"","date":"3 October 2025","externalUrl":null,"permalink":"/tags/genai/","section":"Tags","summary":"","title":"GenAI","type":"tags"},{"content":"","date":"3 October 2025","externalUrl":null,"permalink":"/tags/langchain/","section":"Tags","summary":"","title":"LangChain","type":"tags"},{"content":"","date":"3 October 2025","externalUrl":null,"permalink":"/projects/","section":"Projects (many more to come...)","summary":"","title":"Projects (many more to come...)","type":"projects"},{"content":"","date":"3 October 2025","externalUrl":null,"permalink":"/tags/vectordb/","section":"Tags","summary":"","title":"VectorDB","type":"tags"},{"content":"","date":"12 July 2025","externalUrl":null,"permalink":"/tags/data-analytics/","section":"Tags","summary":"","title":"Data Analytics","type":"tags"},{"content":"","date":"12 July 2025","externalUrl":null,"permalink":"/tags/sql/","section":"Tags","summary":"","title":"SQL","type":"tags"},{"content":"","date":"3 May 2025","externalUrl":null,"permalink":"/tags/faiss/","section":"Tags","summary":"","title":"FAISS","type":"tags"},{"content":"","date":"3 May 2025","externalUrl":null,"permalink":"/tags/rag/","section":"Tags","summary":"","title":"RAG","type":"tags"},{"content":" Applied clustering algorithms to segment candidates and employers based on skills, experience, and hiring patterns, improving relevance in candidate–employer matching workflows. Performed feature engineering and data preprocessing on structured recruitment data to support ML-driven analysis. Experimented with and fine-tuned ML models to improve matching accuracy and reduce noise in recommendations. Conducted exploratory data analysis (EDA) to identify behavioral patterns and trends across candidate datasets. Built interactive Power BI dashboards using DAX to monitor hiring KPIs and model-driven insights. Automated ETL pipelines to clean, transform, and integrate data from multiple sources into ML-ready datasets. Collaborated with cross-functional teams to translate business requirements into data and ML solutions. ","date":"1 May 2025","externalUrl":null,"permalink":"/experience/amiscent/","section":"Experience","summary":"Applied machine learning, clustering, and data-driven optimization for recruitment intelligence systems.","title":"AI \u0026 Data Analyst Intern — Amiscent","type":"experience"},{"content":"","date":"1 May 2025","externalUrl":null,"permalink":"/tags/clustering/","section":"Tags","summary":"","title":"Clustering","type":"tags"},{"content":"","date":"1 May 2025","externalUrl":null,"permalink":"/tags/etl/","section":"Tags","summary":"","title":"ETL","type":"tags"},{"content":"","date":"1 May 2025","externalUrl":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning","type":"tags"},{"content":"","date":"1 May 2025","externalUrl":null,"permalink":"/tags/power-bi/","section":"Tags","summary":"","title":"Power BI","type":"tags"},{"content":"","date":"1 January 2025","externalUrl":null,"permalink":"/tags/hexapod/","section":"Tags","summary":"","title":"Hexapod","type":"tags"},{"content":"","date":"1 January 2025","externalUrl":null,"permalink":"/tags/inverse-kinematics/","section":"Tags","summary":"","title":"Inverse Kinematics","type":"tags"},{"content":"","date":"1 January 2025","externalUrl":null,"permalink":"/tags/robotics/","section":"Tags","summary":"","title":"Robotics","type":"tags"},{"content":"","date":"1 January 2025","externalUrl":null,"permalink":"/tags/ros-2/","section":"Tags","summary":"","title":"ROS 2","type":"tags"},{"content":"","date":"1 January 2025","externalUrl":null,"permalink":"/tags/simulation/","section":"Tags","summary":"","title":"Simulation","type":"tags"},{"content":"","date":"3 December 2024","externalUrl":null,"permalink":"/tags/autonomous-robots/","section":"Tags","summary":"","title":"Autonomous Robots","type":"tags"},{"content":"","date":"3 December 2024","externalUrl":null,"permalink":"/tags/computer-vision/","section":"Tags","summary":"","title":"Computer Vision","type":"tags"},{"content":"","date":"3 October 2024","externalUrl":null,"permalink":"/tags/autonomous-navigation/","section":"Tags","summary":"","title":"Autonomous Navigation","type":"tags"},{"content":"","date":"3 October 2024","externalUrl":null,"permalink":"/tags/drones/","section":"Tags","summary":"","title":"Drones","type":"tags"},{"content":" Implemented Nav2 stack and LiDAR SLAM in ROS 2. Tuned AMCL parameters using data-driven testing. Reduced simulation–hardware latency by ~40%. Authored reusable deployment documentation. ","date":"1 June 2024","externalUrl":null,"permalink":"/experience/alphadroids/","section":"Experience","summary":"ROS 2 navigation, SLAM, and real-world robot deployment.","title":"Robotics Developer Intern — Alphadroids","type":"experience"},{"content":"","date":"1 June 2024","externalUrl":null,"permalink":"/tags/slam/","section":"Tags","summary":"","title":"SLAM","type":"tags"},{"content":"","date":"1 May 2024","externalUrl":null,"permalink":"/tags/ros/","section":"Tags","summary":"","title":"ROS","type":"tags"},{"content":"","date":"1 May 2024","externalUrl":null,"permalink":"/tags/yolov8/","section":"Tags","summary":"","title":"YOLOv8","type":"tags"},{"content":"","date":"1 March 2024","externalUrl":null,"permalink":"/tags/competition/","section":"Tags","summary":"","title":"Competition","type":"tags"},{"content":"","date":"1 March 2024","externalUrl":null,"permalink":"/competitions/","section":"Competitions","summary":"","title":"Competitions","type":"competitions"},{"content":" Overview # Developed an autonomous quadcopter system as part of the IIT Bombay e-Yantra Robotics Competition (2023–24) under the Luminosity Drone theme.\nThe objective was to enable autonomous exploration, detection, and navigation in a simulated environment.\nKey Contributions # Implemented autonomous exploration and waypoint navigation for a quadcopter. Developed object detection and clustering pipelines for scene understanding. Integrated WhyCon-based localization for precise pose estimation. Designed and tuned PID controllers to improve flight stability and accuracy. Created and integrated a custom ROS message format for drone telemetry and control. Technical Stack # Middleware \u0026amp; Simulation: ROS 2, Gazebo, RViz Perception: OpenCV, WhyCon Control: PID Controller, BetaFlight concepts Programming: Python Outcome # Selected as Semi-Finalist at IIT Bombay e-Yantra Robotics Competition. Demonstrated robust autonomous navigation and perception under competition constraints. Gained hands-on experience in aerial robotics, control systems, and ROS-based simulation. ","date":"1 March 2024","externalUrl":null,"permalink":"/competitions/luminosity-drone/","section":"Competitions","summary":"Semi-Finalist project focused on autonomous drone navigation, perception, and control.","title":"IIT Bombay e-Yantra — Luminosity Drone","type":"competitions"},{"content":"","date":"1 March 2024","externalUrl":null,"permalink":"/leadership/","section":"Leadership","summary":"","title":"Leadership","type":"leadership"},{"content":" About the Role # A.T.O.M Robotics Lab is a student-led technical community with the goal of spreading awareness of modern robotics stacks such as ROS, Gazebo, and real-world hardware integration through project-based learning.\nResponsibilities \u0026amp; Impact # Led and mentored 60+ students across robotics and AI projects. Conducted periodic workshops and technical sessions on ROS, simulation, and perception. Actively led and contributed to multiple robotics projects. Organized community sessions, technical events, and intra-college workshops. Handled PR activities and coordinated sponsorships and funding for lab initiatives. ","date":"1 March 2024","externalUrl":null,"permalink":"/leadership/atom-robotics-lab/","section":"Leadership","summary":"Founded and led a robotics and AI community focused on project-based learning.","title":"President — A.T.O.M Robotics Lab","type":"leadership"},{"content":" Overview # Finalist project in Flipkart GRID 5.0 (Robotics Manipulator Theme), focused on designing and developing a 6-DOF robotic arm capable of perception-driven manipulation using computer vision and 3D point cloud processing.\nThe objective was to detect payloads, segment graspable surfaces, and accurately compute transforms for manipulation under real-world constraints.\nKey Contributions # Designed and implemented a 6-DOF robotic arm from scratch using Python and C++. Implemented YOLOv8-based object detection and instance segmentation to identify and isolate payload surfaces. Performed surface extraction using segmentation masks to remove irrelevant regions from point clouds. Generated OctoMap representations of the environment for spatial understanding. Computed precise TF (transform) frames for object localization and manipulation. Applied clustering techniques (DBSCAN, K-Means) for noise filtering and nearest-neighbor analysis in point cloud data. Technical Stack # Perception: YOLOv8, OpenCV 3D Processing: Point Cloud Library (PCL), Open3D Robotics Middleware: ROS, MoveIt Simulation \u0026amp; Visualization: Gazebo, RViz Programming: Python, C++ Outcome \u0026amp; Impact # Achieved Finalist position among national-level teams. Reduced perception-to-action latency by ~60%. Improved payload surface detection accuracy by ~50%. Demonstrated a complete perception → planning → manipulation pipeline under competition constraints. Learnings # This project strengthened my understanding of:\nVision-guided robotic manipulation 3D perception and spatial reasoning ROS-based system integration Designing robust pipelines under strict evaluation criteria ","date":"1 January 2024","externalUrl":null,"permalink":"/competitions/flipkart-grid/","section":"Competitions","summary":"Finalist project involving a vision-guided 6-DOF robotic arm with perception-driven manipulation.","title":"Flipkart GRID 5.0 — Robotics Manipulator Theme","type":"competitions"},{"content":"","date":"1 January 2024","externalUrl":null,"permalink":"/tags/manipulation/","section":"Tags","summary":"","title":"Manipulation","type":"tags"},{"content":" About Me # I’m Aakshar Garg, an AI \u0026amp; Machine Learning engineer working at the intersection of machine learning, computer vision, and robotics AI. I focus on building production-oriented intelligent systems—from data pipelines and model training to perception, autonomy, and real-world deployment.\nMy work spans applied ML and deep learning, where I’ve designed and fine-tuned models for object detection, instance segmentation, clustering, and pattern discovery. I’ve worked extensively with YOLOv8, OpenCV, and classical ML techniques such as DBSCAN and K-Means, applying them to unstructured, noisy data and real-world perception problems.\nIn robotics-centric projects, I’ve applied ML within ROS 2–based systems, combining vision, spatial reasoning, and control. This includes point-cloud processing, surface extraction, octomap generation, transform (TF) estimation, and simulation-to-hardware workflows using Gazebo and GZ-Harmonic. I care deeply about system robustness, interpretability, and real-world performance, not just model accuracy.\nBeyond individual projects, I actively lead and scale teams. As President of A.T.O.M Robotics Lab, I drive project-based learning, mentor students across AI and robotics domains, organize technical workshops and events, and manage sponsorships and collaborations. I’ve also participated in national-level robotics competitions, gaining experience with time-bound, high-pressure engineering problem statements.\nWhat I Work With # Machine Learning \u0026amp; AI # Supervised and unsupervised learning Clustering and pattern discovery (DBSCAN, K-Means) Feature engineering, model fine-tuning, and evaluation End-to-end ML pipeline design Computer Vision \u0026amp; Perception # YOLOv8 object detection and instance segmentation Image processing and depth-based perception Surface extraction and vision-based navigation Robotics \u0026amp; Autonomous Systems # ROS 2, Nav2, Gazebo, GZ-Harmonic, RViz Point clouds, octomaps, TFs, and PID control Simulation-driven development and autonomy workflows Leadership \u0026amp; Competitions # President, A.T.O.M Robotics Lab Led 60+ students across AI and robotics projects Organized workshops, technical events, and industry initiatives Secured funding and sponsorships Finalist – Flipkart Grid 5.0 (Robotic Manipulator Track) Semi-Finalist – IIT Bombay eYantra Robotics Competition What Drives Me # I enjoy working on problems where AI meets reality—clean architectures, scalable systems, and intelligent solutions that operate reliably outside controlled demos. I’m particularly interested in opportunities involving applied machine learning, perception systems, robotics AI, and intelligent automation.\n","date":"20 September 2004","externalUrl":null,"permalink":"/about/","section":"Home","summary":"","title":"About","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":" GenAI \u0026amp; AI Systems # LangChain, LangGraph, RAG Engines, ChromaDB, FAISS, HuggingFace, Groq, Vector Embeddings\nBackend \u0026amp; Data # FastAPI, Celery, Streamlit, Web Crawling, MySQL, PostgreSQL, MongoDB, Docker, Redis\nAnalytics \u0026amp; BI # Data Wrangling, Power BI, Tableau, Excel, Power Query, DAX\nProgramming # Python, C, C++\nSoft Skills # Leadership, Communication, Report Writing, Problem Solving\n","externalUrl":null,"permalink":"/skills/","section":"Skills","summary":"","title":"Skills","type":"skills"}]